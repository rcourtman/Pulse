{{- if .Values.monitoring.prometheusRule.enabled -}}
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: {{ include "pulse.fullname" . }}-ai-explore
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "pulse.labels" . | nindent 4 }}
    {{- with .Values.monitoring.prometheusRule.labels }}
    {{- toYaml . | nindent 4 }}
    {{- end }}
  {{- with .Values.monitoring.prometheusRule.annotations }}
  annotations:
    {{- toYaml . | nindent 4 }}
  {{- end }}
spec:
  groups:
    - name: {{ include "pulse.fullname" . }}.ai.explore
      rules:
        - record: pulse_ai_explore_failure_rate
          expr: |
            (
              sum(rate(pulse_ai_explore_runs_total{outcome="failed"}[{{ .Values.monitoring.prometheusRule.failureRate.window }}]))
              /
              clamp_min(sum(rate(pulse_ai_explore_runs_total[{{ .Values.monitoring.prometheusRule.failureRate.window }}])), 1)
            )
        - record: pulse_ai_explore_p95_duration_seconds
          expr: |
            histogram_quantile(
              0.95,
              sum by (le) (rate(pulse_ai_explore_duration_seconds_bucket{outcome="success"}[{{ .Values.monitoring.prometheusRule.p95Duration.window }}]))
            )
        - record: pulse_ai_explore_skipped_no_model_total
          expr: |
            increase(pulse_ai_explore_runs_total{outcome="skipped_no_model"}[{{ .Values.monitoring.prometheusRule.skippedNoModel.window }}])
        {{- if .Values.monitoring.prometheusRule.failureRate.enabled }}
        - alert: PulseAIExploreFailureRateHigh
          expr: |
            pulse_ai_explore_failure_rate > {{ .Values.monitoring.prometheusRule.failureRate.threshold }}
            and
            sum(increase(pulse_ai_explore_runs_total[{{ .Values.monitoring.prometheusRule.failureRate.window }}])) >= {{ .Values.monitoring.prometheusRule.failureRate.minRuns }}
          for: {{ .Values.monitoring.prometheusRule.failureRate.for }}
          labels:
            severity: {{ .Values.monitoring.prometheusRule.failureRate.severity | quote }}
          annotations:
            summary: Explore pre-pass failure rate is high
            description: Explore pre-pass failures exceeded threshold for sustained traffic.
        {{- end }}
        {{- if .Values.monitoring.prometheusRule.p95Duration.enabled }}
        - alert: PulseAIExploreP95DurationHigh
          expr: pulse_ai_explore_p95_duration_seconds > {{ .Values.monitoring.prometheusRule.p95Duration.thresholdSeconds }}
          for: {{ .Values.monitoring.prometheusRule.p95Duration.for }}
          labels:
            severity: {{ .Values.monitoring.prometheusRule.p95Duration.severity | quote }}
          annotations:
            summary: Explore pre-pass latency p95 is high
            description: Explore pre-pass p95 duration is above the configured threshold.
        {{- end }}
        {{- if .Values.monitoring.prometheusRule.skippedNoModel.enabled }}
        - alert: PulseAIExploreSkippedNoModel
          expr: pulse_ai_explore_skipped_no_model_total > {{ .Values.monitoring.prometheusRule.skippedNoModel.threshold }}
          for: {{ .Values.monitoring.prometheusRule.skippedNoModel.for }}
          labels:
            severity: {{ .Values.monitoring.prometheusRule.skippedNoModel.severity | quote }}
          annotations:
            summary: Explore pre-pass is skipping due to missing explicit model
            description: Explore pre-pass skipped because no explicit model was configured.
        {{- end }}
{{- end }}
